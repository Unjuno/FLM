# モデル生成パラメータ・メモリ設定機能のテスト手順

## テスト項目

### 1. UI表示の確認
- [ ] API作成画面で「高度な設定: モデル生成パラメータ」セクションが表示される
- [ ] セクションが折りたたまれている状態で開始される
- [ ] クリックで展開/折りたたみができる
- [ ] 各パラメータの入力フィールドが正しく表示される

### 2. デフォルト値の確認
- [ ] 温度: 0.7
- [ ] Top-p: 0.9
- [ ] Top-k: 40
- [ ] 最大トークン数: 1024
- [ ] 繰り返しペナルティ: 1.1
- [ ] シード値: 未指定（空）

### 3. 入力値のバリデーション
- [ ] 温度に-0.1を入力 → エラーメッセージ表示
- [ ] 温度に2.1を入力 → エラーメッセージ表示
- [ ] 温度に0.0を入力 → エラーなし
- [ ] 温度に2.0を入力 → エラーなし
- [ ] Top-pに-0.1を入力 → エラーメッセージ表示
- [ ] Top-pに1.1を入力 → エラーメッセージ表示
- [ ] Top-kに0を入力 → エラーメッセージ表示
- [ ] Top-kに101を入力 → エラーメッセージ表示
- [ ] 最大トークン数に0を入力 → エラーメッセージ表示

### 4. デフォルト値リセットボタン
- [ ] パラメータを変更後、「デフォルト値にリセット」ボタンをクリック
- [ ] すべての値がデフォルト値に戻る

### 5. データ送信の確認
- [ ] ブラウザの開発者ツールでコンソールを開く
- [ ] API作成画面でパラメータを設定
- [ ] 「作成」ボタンをクリック
- [ ] コンソールに「API作成 - 送信する設定:」が表示される
- [ ] `model_parameters`が正しく含まれていることを確認
- [ ] 設定した値が正しくJSONに含まれていることを確認

### 6. メモリ・リソース設定の確認
- [ ] API作成画面で「メモリ・リソース設定」セクションが表示される
- [ ] セクションが折りたたまれている状態で開始される
- [ ] クリックで展開/折りたたみができる
- [ ] コンテキストウィンドウサイズの入力フィールドが表示される
- [ ] GPUレイヤー数の入力フィールドが表示される
- [ ] CPUスレッド数の入力フィールドが表示される
- [ ] バッチサイズの入力フィールドが表示される（デフォルト: 512）
- [ ] メモリマップドファイル使用のチェックボックスが表示される（デフォルト: 有効）
- [ ] メモリロックのチェックボックスが表示される（デフォルト: 無効）
- [ ] 低メモリモードのチェックボックスが表示される（デフォルト: 無効）

### 7. メモリ設定のバリデーション
- [ ] コンテキストウィンドウサイズに127を入力 → エラーメッセージ表示
- [ ] コンテキストウィンドウサイズに128を入力 → エラーなし
- [ ] GPUレイヤー数に-1を入力 → エラーメッセージ表示
- [ ] GPUレイヤー数に0を入力 → エラーなし（CPUのみ）
- [ ] CPUスレッド数に0を入力 → エラーメッセージ表示
- [ ] バッチサイズに0を入力 → エラーメッセージ表示

### 8. メモリ設定のデフォルト値リセット
- [ ] メモリ設定を変更後、「メモリ設定をデフォルト値にリセット」ボタンをクリック
- [ ] バッチサイズが512に戻る
- [ ] use_mmapがtrueに戻る
- [ ] use_mlockがfalseに戻る
- [ ] low_memがfalseに戻る

### 9. データ送信の確認
- [ ] ブラウザの開発者ツールでコンソールを開く
- [ ] API作成画面でメモリ設定を変更
- [ ] 「作成」ボタンをクリック
- [ ] コンソールに「API作成 - 送信する設定:」が表示される
- [ ] `model_parameters.memory`が正しく含まれていることを確認
- [ ] 設定したメモリ値が正しくJSONに含まれていることを確認

### 10. バックエンドでの受信確認
- [ ] バックエンドのログで`engine_config`が正しく受信されることを確認
- [ ] `model_parameters`が正しくパースされることを確認
- [ ] `model_parameters.memory`が正しくパースされることを確認

## テスト実行コマンド

```bash
# 開発サーバーを起動
npm run dev

# ブラウザで http://localhost:1420 を開く
# 開発者ツール（F12）でコンソールタブを開く
# API作成画面に移動してテストを実行
```

## 期待される動作

1. **フォーム表示**: 
   - 高度な設定セクションは折りたたまれた状態で表示
   - メモリ・リソース設定セクションも折りたたまれた状態で表示
2. **展開**: 
   - クリックで展開し、6つのパラメータ入力フィールドが表示（モデル生成パラメータ）
   - クリックで展開し、7つの設定項目が表示（メモリ・リソース設定）
3. **デフォルト値**: 
   - モデル生成パラメータ: 各フィールドにデフォルト値が設定されている
   - メモリ設定: バッチサイズ=512、use_mmap=true、use_mlock=false、low_mem=false
4. **バリデーション**: 範囲外の値を入力するとエラーメッセージが表示
5. **リセット**: 
   - 「デフォルト値にリセット」ボタンでモデル生成パラメータがデフォルト値に戻る
   - 「メモリ設定をデフォルト値にリセット」ボタンでメモリ設定がデフォルト値に戻る
6. **送信**: 設定した値が`engine_config`のJSONに`model_parameters`として含まれ、その中に`memory`設定も含まれて送信される

## デバッグ情報

コンソールに以下のようなログが出力されるはずです：

```
ApiConfigForm - 送信する設定: {
  name: "LocalAI API",
  port: 8080,
  enableAuth: true,
  engineType: "ollama",
  modelParameters: {
    temperature: 0.7,
    top_p: 0.9,
    top_k: 40,
    max_tokens: 1024,
    repeat_penalty: 1.1
  }
}

API作成 - 送信する設定: {
  name: "LocalAI API",
  model_name: "llama3:8b",
  port: 8080,
  enable_auth: true,
  engine_type: "ollama",
  engine_config: "{\"model_parameters\":{\"temperature\":0.7,\"top_p\":0.9,\"top_k\":40,\"max_tokens\":1024,\"repeat_penalty\":1.1,\"memory\":{\"context_window\":4096,\"num_gpu_layers\":20,\"batch_size\":512,\"use_mmap\":true,\"use_mlock\":false,\"low_mem\":false}}}",
  model_parameters: {
    temperature: 0.7,
    top_p: 0.9,
    top_k: 40,
    max_tokens: 1024,
    repeat_penalty: 1.1,
    memory: {
      context_window: 4096,
      num_gpu_layers: 20,
      batch_size: 512,
      use_mmap: true,
      use_mlock: false,
      low_mem: false
    }
  }
}
```

