# FLM - 証明書自動生成機能 実行テストガイド

## 🧪 テスト概要

証明書自動生成機能が正常に動作するかテストします。

---

## ✅ 実装済み機能

### 1. 自動証明書生成
- 証明書がない場合、自動的に生成
- OpenSSLを使用（標準的な方法）
- ユーザー操作不要

### 2. HTTPS必須化
- HTTPモードは完全に無効化
- すべての通信がHTTPSで暗号化
- パスワード漏洩を防止

---

## 🚀 実行テスト方法

### 方法1: 自動テスト実行（推奨）

証明書自動生成機能のテストを自動実行します。

#### Windows (PowerShell)
```powershell
.\scripts\test-certificate-generation.ps1
```

#### macOS/Linux (Bash)
```bash
chmod +x scripts/test-certificate-generation.sh
./scripts/test-certificate-generation.sh
```

#### npmスクリプトを使用（推奨）
```bash
# 証明書自動生成テストを実行（Tauri不要）
npm run test:certificate
```

### 方法2: Tauriアプリケーションから実行

1. **アプリケーションを起動**
   ```bash
   npm run tauri:dev
   ```

2. **APIを作成して起動**
   - アプリケーション内で新しいAPIを作成
   - API起動時に証明書が自動生成される

3. **確認**
   - コンソールに以下のメッセージが表示される:
     ```
     🔒 HTTPS証明書を自動生成中...（初回のみ、しばらくお待ちください）
     ✅ HTTPS証明書の生成が完了しました
     ✅ HTTPS認証プロキシサーバーが起動しました: https://0.0.0.0:8081
     ```

### 方法3: 認証プロキシサーバーを直接起動

1. **環境変数を設定**
   ```bash
   $env:PORT="8080"
   $env:API_ID="test-api-123"
   $env:ENGINE_BASE_URL="http://localhost:11434"
   ```

2. **サーバーを起動**
   ```bash
   cd src/backend/auth
   node server.js
   ```

3. **確認**
   - 証明書がない場合、自動生成される
   - HTTPSサーバーが起動する

---

## 📋 テストチェックリスト

### ✅ 証明書生成の確認

- [ ] 証明書ファイルが作成される
  - パス: `%LOCALAPPDATA%\FLM\certificates\{API_ID}.pem`
  - パス: `%LOCALAPPDATA%\FLM\certificates\{API_ID}.key`

- [ ] 証明書が正しく生成される
  - ファイルサイズが0より大きい
  - PEM形式で保存されている

- [ ] 証明書に適切なホスト名が含まれる
  - `localhost`
  - `127.0.0.1`
  - ローカルIPアドレス（検出可能な場合）

### ✅ HTTPSサーバー起動の確認

- [ ] HTTPSサーバーが起動する
  - ポート: `元のポート + 1`（例: 8080 → 8081）

- [ ] HTTPリダイレクトが機能する
  - `http://localhost:8080` → `https://localhost:8081`

- [ ] HTTPSでアクセス可能
  - `https://localhost:8081` でアクセスできる
  - ブラウザで警告が表示される（自己署名証明書のため正常）

### ✅ セキュリティの確認

- [ ] HTTPモードが無効化されている
  - 証明書がない場合、HTTPで起動しない

- [ ] 証明書がない場合、自動生成される
  - エラーを表示せず、自動的に生成

- [ ] すべての通信がHTTPSで暗号化される
  - APIキーが平文で送信されることはない

---

## 🔍 トラブルシューティング

### OpenSSLが見つからない

**エラーメッセージ:**
```
証明書生成エラー: Error: 証明書生成に失敗しました。OpenSSLがインストールされていない可能性があります。
```

**解決方法:**
- Windows: Git for Windowsをインストール（OpenSSLが含まれます）
- macOS/Linux: `brew install openssl` または `apt-get install openssl`

### 証明書生成に失敗する

**確認事項:**
1. データディレクトリの書き込み権限を確認
2. ディスク容量を確認
3. OpenSSLが正しくインストールされているか確認

### HTTPSサーバーが起動しない

**確認事項:**
1. ポート番号が他のアプリで使用されていないか確認
2. 証明書ファイルが正しく生成されているか確認
3. コンソールログでエラーメッセージを確認

---

## 📝 テスト結果の記録

### 正常な動作例

```
🔒 HTTPS証明書が見つかりません。自動生成します...
🔒 HTTPS証明書を自動生成中...（初回のみ、しばらくお待ちください）
✅ HTTPS証明書の自動生成が完了しました
HTTPリダイレクトサーバーが起動しました: http://0.0.0.0:8080 → https://0.0.0.0:8081
✅ HTTPS認証プロキシサーバーが起動しました: https://0.0.0.0:8081
   ローカルアクセス: https://localhost:8081
   外部アクセス: ネットワーク上の他のデバイスからもアクセス可能です
   ⚠️  自己署名証明書のため、ブラウザで警告が表示されます（正常です）
```

---

## 🎯 次のステップ

テストが成功したら:
1. 実際のAPIを使用してHTTPS通信をテスト
2. ブラウザでAPIエンドポイントにアクセスして確認
3. 外部デバイスからアクセスして外部公開を確認

---

# FLM - マルチエンジン対応機能 実行テストガイド

## 🧪 テスト概要

マルチエンジン対応機能が正常に動作するかテストします。
複数のLLMエンジン（Ollama、LM Studio、vLLM、llama.cpp）を切り替えて使用できることを確認します。

---

## ✅ 実装済み機能

### 1. エンジン管理機能
- 利用可能なエンジン一覧の取得
- エンジンの自動検出（インストール済み・実行中を確認）
- エンジン別のモデル一覧取得

### 2. マルチエンジン対応API作成
- エンジンタイプを指定してAPIを作成
- エンジン固有設定（engine_config）の保存
- デフォルトエンジン（Ollama）の自動選択

### 3. エンジン設定管理
- エンジン設定の保存・取得・削除
- 複数エンジン設定の管理
- デフォルトエンジンの設定

---

## 🚀 実行テスト方法

### 方法1: 自動テスト実行スクリプト（推奨）

Windows環境では、PowerShellスクリプトを使用して自動的にテストを実行できます：

```powershell
.\run-tests-with-tauri.ps1
```

このスクリプトは：
- Tauriアプリの起動を確認
- 単体テストを実行
- F001 API作成機能テストを実行
- マルチエンジン対応機能テストを実行

### 方法2: 統合テストを手動実行

1. **Tauriアプリケーションを起動**（別ターミナル）
   ```bash
   npm run tauri:dev
   ```
   - アプリが完全に起動するまで待つ（約10-20秒）

2. **マルチエンジンテストを実行**
   ```bash
   npm test -- tests/integration/multi-engine.test.ts
   ```

3. **確認**
   - すべてのテストケースが成功（PASS）することを確認
   - エラーメッセージがないことを確認

### 方法3: アプリケーションから手動テスト

1. **アプリケーションを起動**
   ```bash
   npm run tauri:dev
   ```

2. **エンジン選択UIを確認**
   - 「API作成」画面に移動
   - 「モデル選択」画面でエンジン選択ドロップダウンを確認
   - 「設定」画面でエンジン選択を確認

3. **エンジン別のモデル一覧を確認**
   - エンジンを選択すると、そのエンジンのモデル一覧が表示される
   - Ollama: `get_models_list`コマンドを使用
   - その他: `get_engine_models`コマンドを使用

4. **エンジン指定でAPIを作成**
   - 異なるエンジンを選択してAPIを作成
   - データベースに`engine_type`が保存されることを確認

---

## 📋 テストチェックリスト

### ✅ エンジン管理機能の確認

- [ ] 利用可能なエンジン一覧を取得できる
  - `get_available_engines`コマンドが動作する
  - 最低限、'ollama'が含まれている
  - 期待されるエンジンタイプ（'lm_studio', 'vllm', 'llama_cpp'）が含まれている可能性がある

- [ ] エンジン検出機能が動作する
  - `detect_engine`で個別エンジンを検出できる
  - `detect_all_engines`で全エンジンを検出できる
  - 検出結果に`installed`と`running`の状態が含まれる

- [ ] エンジン別のモデル一覧を取得できる
  - `get_engine_models`でエンジン別モデル一覧を取得できる
  - Ollamaの場合は既存の`get_models_list`も動作する
  - 存在しないエンジンタイプで適切なエラーが返る

### ✅ マルチエンジン対応API作成の確認

- [ ] エンジンタイプを指定してAPIを作成できる
  - `engine_type`パラメータを指定してAPIを作成
  - データベースに`engine_type`が保存される
  - デフォルトで'ollama'が使用される（未指定時）

- [ ] エンジン固有設定が保存される
  - `engine_config`（JSON形式）が保存される
  - API詳細取得時に`engine_config`が取得できる
  - JSON形式で正しく保存・取得できる

- [ ] API起動時にエンジンが自動起動される
  - エンジンが停止している場合、自動的に起動される
  - エンジンのベースURLが正しく設定される
  - 認証プロキシがエンジンのベースURLを使用する

### ✅ UI機能の確認

- [ ] モデル選択画面でエンジン選択ができる
  - エンジン選択ドロップダウンが表示される
  - エンジン変更時にモデル一覧が更新される
  - 選択したエンジンがAPI設定に反映される

- [ ] API設定画面でエンジン選択ができる
  - エンジン選択ドロップダウンが表示される
  - 利用可能なエンジン一覧が表示される
  - エンジン名が日本語で表示される（Ollama、LM Studioなど）

### ✅ エンジン設定管理の確認

- [ ] エンジン設定を保存できる
  - `save_engine_config`コマンドが動作する
  - 設定IDが返される
  - データベースに保存される

- [ ] エンジン設定一覧を取得できる
  - `get_engine_configs`コマンドが動作する
  - エンジンタイプでフィルタできる
  - 設定一覧が正しく取得できる

- [ ] エンジン設定を削除できる
  - `delete_engine_config`コマンドが動作する
  - 設定が正しく削除される

---

## 🔍 トラブルシューティング

### エンジン一覧が取得できない

**エラーメッセージ:**
```
Error: invoke is not a function
```

**解決方法:**
- Tauriアプリケーションが起動しているか確認
- アプリが完全に起動するまで待つ（約10-20秒）

### エンジンが検出されない

**エラーメッセージ:**
```
エンジン検出エラー: ...
```

**解決方法:**
- エンジンが実際にインストールされているか確認
- エンジンが起動しているか確認（Ollamaなど）
- エンジンの実行ファイルパスが正しいか確認

### モデル一覧が取得できない

**エラーメッセージ:**
```
Ollamaが起動していません。Ollamaを起動してから再度お試しください。
```

**解決方法:**
- エンジン（Ollamaなど）が起動しているか確認
- エンジンのベースURLが正しいか確認（デフォルト: http://localhost:11434）
- ネットワーク接続を確認

### API作成時にエンジンが起動しない

**エラーメッセージ:**
```
エンジンの起動に失敗しました: ...
```

**解決方法:**
- エンジンがインストールされているか確認
- エンジンの実行ファイルパスが正しいか確認
- ポート番号が他のアプリで使用されていないか確認
- 手動でエンジンを起動してから再度お試しください

---

## 📝 テスト結果の記録

### 正常な動作例

```
利用可能なエンジン: ['ollama', 'lm_studio', 'vllm', 'llama_cpp']
Ollama検出結果: { engine_type: 'ollama', installed: true, running: true, ... }
Ollamaモデル数: 3
OllamaエンジンでAPIを作成: api-12345-67890
デフォルトエンジンでAPIを作成: api-abcde-fghij
エンジン設定を保存: config-xyz-123
エンジン設定数: 2
```

---

## 🎯 次のステップ

テストが成功したら:
1. 実際に異なるエンジンでAPIを作成して動作確認
2. エンジン切り替え時のモデル一覧更新を確認
3. エンジン固有設定の動作を確認
4. 複数エンジンを同時に使用できることを確認

---

---

## 📚 関連ドキュメント

- **単体テスト**: `tests/unit/certificate-generation.test.ts`
- **統合テスト**: `tests/integration/certificate-auto-generation.test.ts`
- **テストスクリプト**: 
  - Windows: `scripts/test-certificate-generation.ps1`
  - macOS/Linux: `scripts/test-certificate-generation.sh`

---

**最終更新**: 2024年

