# FLM 使用可能状況

## ✅ 現在の実装状況

### 🎯 コア機能（使用可能）

以下の機能は**実装済みで使用可能**です：

#### 1. **API作成機能（F001）** ✅
- モデル選択からAPI作成まで完全実装
- 自動HTTPS証明書生成
- APIキー自動生成・暗号化保存
- Ollama自動起動・確認

#### 2. **API利用機能（F002）** ✅
- テスト用チャットインターフェース
- OpenAI互換API形式
- サンプルコード自動生成

#### 3. **API管理機能（F003）** ✅
- API起動/停止
- 設定変更（ポート、認証）
- API削除

#### 4. **モデル管理機能（F004）** ✅
- モデル検索・フィルタ
- モデルダウンロード
- インストール済みモデル一覧

#### 5. **認証機能（F005）** ✅
- APIキー生成・管理
- Bearer Token認証
- 暗号化保存

#### 6. **Ollama自動インストール（F009）** ✅
- システムパス検出
- 自動ダウンロード
- 自動起動

#### 7. **HTTPS対応** ✅
- 自動証明書生成
- HTTPSサーバー起動
- HTTP→HTTPS自動リダイレクト

#### 8. **外部公開対応** ✅
- 0.0.0.0でリッスン（ローカルネットワーク対応）
- エンドポイントURL自動表示（localhost + ローカルIP）

---

## 🚀 使用方法

### 前提条件

1. **Node.js**: インストール済み（v18以上推奨）
2. **Rust**: インストール済み（Tauri開発用）
3. **Ollama**: インストール済み（またはアプリから自動インストール）

### 起動方法

```bash
# 1. 依存関係のインストール
npm install

# 2. 開発モードで起動
npm run tauri:dev
```

### 基本的な使い方

1. **アプリ起動**: `npm run tauri:dev`で起動
2. **API作成**: 
   - ホーム画面から「新しいAPIを作成」をクリック
   - モデルを選択（例: `llama3:8b`）
   - ポート番号を設定（例: `8080`）
   - 認証を有効化（推奨）
   - 「作成」をクリック
3. **API起動**: 作成したAPIを「起動」ボタンで起動
4. **利用**: 
   - テスト画面でAPIをテスト
   - または、エンドポイントURLを使用して外部からアクセス

---

## ⚠️ 既知の問題・制限事項

### 証明書生成について

- **自己署名証明書**: ブラウザで警告が表示されます（正常です）
- **証明書の有効期限**: 2035年まで有効
- **ホスト名**: localhostとローカルIPに対応

### ポート番号について

- **HTTPポート**: 指定したポート（例: 8080）
- **HTTPSポート**: HTTPポート+1（例: 8081）
- **ポート競合**: 他のアプリが使用しているポートは使用できません

---

## 🔍 トラブルシューティング

### アプリが起動しない

1. **ポート1420が使用中**: `.\fix-port-1420.ps1`を実行
2. **Nodeプロセスが残っている**: `Get-Process node | Stop-Process -Force`
3. **Tauri設定エラー**: `tauri.conf.json`の`bundle.targets`を確認

### APIが起動しない

1. **Ollamaが起動していない**: アプリが自動起動を試みます
2. **ポートが使用中**: 別のポート番号を試してください
3. **証明書エラー**: 証明書が自動生成されますが、失敗する場合はHTTPモードで動作します

### 外部からアクセスできない

1. **ファイアウォール**: Windowsファイアウォールでポートを開放
2. **同一ネットワーク**: 同じWi-Fi/LANに接続されていることを確認
3. **IPアドレス**: エンドポイントURLに表示されているIPアドレスを確認

---

## 📝 次のステップ（将来の機能）

- ⏳ レート制限機能
- ⏳ 正式なSSL証明書サポート（Let's Encrypt）
- ⏳ より詳細なパフォーマンス監視
- ⏳ アラート機能の強化

---

**最終更新**: 2024年

